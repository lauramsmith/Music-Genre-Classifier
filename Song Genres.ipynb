{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import tensorflow as tf\n",
    "from datascience import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyrics = Table().read_table('lyrics.csv')\n",
    "altered = lyrics.select(np.arange(2, lyrics.num_columns))\n",
    "altered.to_csv('genreAndProp.csv')\n",
    "# propsOnly = lyrics.select(np.arange(3, lyrics.num_columns))\n",
    "# genresOnly = Table().with_columns('Country', lyrics.apply(lambda x: ((int) (x=='Country')) , 'Genre'), 'Hip-hop', lyrics.apply(lambda x: ((int) (x=='Hip-hop')) , 'Genre'))\n",
    "# propsOnly.to_csv('lyricsProps.csv')\n",
    "# genresOnly.to_csv('lyricsGenres.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input vectors are of length 4816, because we have 4816 words.\n",
    "Our output vectors are of length 2, and are a softmax. 1 in the first position means country, 1 in the second position means hip hop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([\"lyricsProps.csv\", \"lyricsGenres.csv\"], num_epochs = 6)\n",
    "\n",
    "reader = tf.TextLineReader(skip_header_lines=1)\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the\n",
    "# decoded result.\n",
    "record_defaults = [[0] for _ in range(4819)]\n",
    "reading = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "features = tf.stack(reading[0:len(reading)-2])\n",
    "genres = tf.stack(reading[len(reading)-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_file_reader_ops(filename_queue):\n",
    "    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    _, csv_row = reader.read(filename_queue)\n",
    "    record_defaults = [[0] for _ in range(4819)]\n",
    "    reading = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "    features = tf.stack(reading[0:len(reading)-2])\n",
    "    genres = tf.stack(reading[len(reading)-2:])\n",
    "    return features, genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = \"genreAndProp.csv\"\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    tf.train.match_filenames_once(directory),\n",
    "    shuffle=True)\n",
    "\n",
    "# Each file will have a header, we skip it and give defaults and type information\n",
    "# for each column below.\n",
    "line_reader = tf.TextLineReader(skip_header_lines=1)\n",
    "\n",
    "_, csv_row = line_reader.read(filename_queue)\n",
    "\n",
    "# Type information and column names based on the decoded CSV.\n",
    "record_defaults = [[\"\"]] + [[0.0] for _ in range(4817)]\n",
    "readings = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "# Turn the features back into a tensor.\n",
    "features = tf.stack(readings[1:])\n",
    "genre = readings[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer.run()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    # We do 10 iterations (steps) where we grab an example from the CSV file. \n",
    "    for iteration in range(1, 11):\n",
    "        # Our graph isn't evaluated until we use run unless we're in an interactive session.\n",
    "        example, label = sess.run([features, genre])\n",
    "\n",
    "        print(example, label)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country,01\n",
      "Hip-hop,10\n"
     ]
    }
   ],
   "source": [
    "all_genres = [\"Country\", \"Hip-hop\"]\n",
    "onehot = {}\n",
    "# Target number of species types (target classes) is 3 ^\n",
    "genre_count = len(all_genres)\n",
    "\n",
    "# Print out each one-hot encoded string for 3 species.\n",
    "for i, genre in enumerate(all_genres):\n",
    "    # %0*d gives us the second parameter's number of spaces as padding.\n",
    "    print(\"%s,%0*d\" % (genre, genre_count, 10 ** i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 4817])\n",
    "W = tf.Variable(tf.zeros([4817, 2]))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-f2ae0917dc06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenre\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m             raise TypeError('The value of a feed cannot be a tf.Tensor object. '\n\u001b[0m\u001b[1;32m    937\u001b[0m                             \u001b[0;34m'Acceptable feed values include Python scalars, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                             'strings, lists, numpy ndarrays, or TensorHandles.')\n",
      "\u001b[0;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# sess = tf.InteractiveSession()\n",
    "# tf.global_variables_initializer().run()\n",
    "# for _ in range(1000):\n",
    "#   batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "#   sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    while True:\n",
    "        try:\n",
    "            example_data, genre_data = sess.run(train_step, feed_dict={x: features, y_: genre})\n",
    "            print(example_data, genre_data)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mApplications\u001b[m\u001b[m                \u001b[34mPictures\u001b[m\u001b[m\r\n",
      "\u001b[34mDesktop\u001b[m\u001b[m                     \u001b[34mPublic\u001b[m\u001b[m\r\n",
      "\u001b[34mDocuments\u001b[m\u001b[m                   Untitled.ipynb\r\n",
      "\u001b[34mDownloads\u001b[m\u001b[m                   java_error_in_idea_6093.log\r\n",
      "\u001b[34mInfinityFinancial\u001b[m\u001b[m           \u001b[34mlearning-git\u001b[m\u001b[m\r\n",
      "\u001b[34mLibrary\u001b[m\u001b[m                     lyrics.csv\r\n",
      "\u001b[34mLinkedList\u001b[m\u001b[m                  \u001b[34mtemp\u001b[m\u001b[m\r\n",
      "\u001b[34mMovies\u001b[m\u001b[m                      vectorLyrics.csv\r\n",
      "\u001b[34mMusic\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
