{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import tensorflow as tf\n",
    "from datascience import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lyrics = Table().read_table('lyrics.csv')\n",
    "# altered = lyrics.select(np.arange(2, lyrics.num_columns))\n",
    "# altered.to_csv('genreAndProp.csv')\n",
    "table = Table().read_table('vectorLyrics.csv')\n",
    "# propsOnly = lyrics.select(np.arange(3, lyrics.num_columns))\n",
    "# genresOnly = Table().with_columns('Country', lyrics.apply(lambda x: ((int) (x=='Country')) , 'Genre'), 'Hip-hop', lyrics.apply(lambda x: ((int) (x=='Hip-hop')) , 'Genre'))\n",
    "# propsOnly.to_csv('lyricsProps.csv')\n",
    "# genresOnly.to_csv('lyricsGenres.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input vectors are of length 4816, because we have 4816 words.\n",
    "Our output vectors are of length 2, and are a softmax. 1 in the first position means country, 1 in the second position means hip hop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([\"lyricsProps.csv\", \"lyricsGenres.csv\"], num_epochs = 6)\n",
    "\n",
    "reader = tf.TextLineReader(skip_header_lines=1)\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the\n",
    "# decoded result. \n",
    "record_defaults = [[0] for _ in range(4819)]\n",
    "reading = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "features = tf.stack(reading[0:len(reading)-2])\n",
    "genres = tf.stack(reading[len(reading)-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_file_reader_ops(filename_queue):\n",
    "    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    _, csv_row = reader.read(filename_queue)\n",
    "    record_defaults = [[0] for _ in range(4819)]\n",
    "    reading = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "    features = tf.stack(reading[0:len(reading)-2])\n",
    "    genres = tf.stack(reading[len(reading)-2:])\n",
    "    return features, genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5460e1de12b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"vectorLyrics.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m filename_queue = tf.train.string_input_producer(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_filenames_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     shuffle=True)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "directory = \"vectorLyrics.csv\"\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    tf.train.match_filenames_once(directory),\n",
    "    shuffle=True)\n",
    "\n",
    "# Each file will have a header, we skip it and give defaults and type information\n",
    "# for each column below.\n",
    "line_reader = tf.TextLineReader(skip_header_lines=1)\n",
    "\n",
    "_, csv_row = line_reader.read(filename_queue)\n",
    "\n",
    "# Type information and column names based on the decoded CSV.\n",
    "record_defaults = [[0.0] for _ in range(4817)]+[[0], [0]]\n",
    "readings = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "# Turn the features back into a tensor.\n",
    "features = tf.stack(readings[:4817])\n",
    "genre = readings[4817:]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    # We do 10 iterations (steps) where we grab an example from the CSV file. \n",
    "    for iteration in range(1, 11):\n",
    "        # Our graph isn't evaluated until we use run unless we're in an interactive session.\n",
    "        example, label = sess.run([features, genre])\n",
    "\n",
    "        print(example, label)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country,01\n",
      "Hip-hop,10\n"
     ]
    }
   ],
   "source": [
    "all_genres = [\"Country\", \"Hip-hop\"]\n",
    "onehot = {}\n",
    "# Target number of species types (target classes) is 3 ^\n",
    "genre_count = len(all_genres)\n",
    "\n",
    "# Print out each one-hot encoded string for 3 species.\n",
    "for i, genre in enumerate(all_genres):\n",
    "    # %0*d gives us the second parameter's number of spaces as padding.\n",
    "    print(\"%s,%0*d\" % (genre, genre_count, 10 ** i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 4976])\n",
    "W = tf.Variable(tf.zeros([4976, 2]))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4978\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f5df75e7cd43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4976\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mgenre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4976\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenre\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# sess = tf.InteractiveSession()\n",
    "# tf.global_variables_initializer().run()\n",
    "# for _ in range(1000):\n",
    "#   batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "#   sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "print(table.num_columns)\n",
    "with tf.InteractiveSession() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "    count = 0\n",
    "    while count < table.num_rows:\n",
    "        try:\n",
    "            arr = np.array(table.row(count))\n",
    "            features = [arr[:4976]]\n",
    "            genre = [arr[4976:]]\n",
    "            example_data, genre_data = sess.run(train_step, feed_dict={x: features, y_: genre})\n",
    "            print(example_data, genre_data)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent_1' type=NoOp>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
